{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we provide the hardcoded construction of a 3-layer BaseConv model that implements gradient descent on least squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append(\"/scratch/precision-ls/\")\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import einsum\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models import build_model\n",
    "from src.datagen.main import LeastSquaresSampler, ExplicitGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def adjust_lightness(color, lightness):\n",
    "    hsv = color.copy()\n",
    "    hsv[2] = lightness\n",
    "    return mcolors.hsv_to_rgb(hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem settings\n",
    "n_dims = 5\n",
    "n_points = 20\n",
    "batch_size = 16\n",
    "\n",
    "# Model settings\n",
    "n_layer = 3\n",
    "n_embd = 4*n_dims + 1\n",
    "n_model_dims = n_dims + 1\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Gradient descent\n",
    "lr = 0.1\n",
    "num_iters = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers for setting model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually initialize weights\n",
    "def set_param(param, setting=None, bias=True, requires_grad=False, device=\"cuda\"):\n",
    "    if setting == \"identity\":\n",
    "        param.weight = torch.nn.Parameter(torch.eye(*param.weight.shape).to(device))\n",
    "        param.weight.requires_grad = requires_grad\n",
    "        if bias:\n",
    "            param.bias = torch.nn.Parameter(torch.zeros(*param.bias.shape).to(device))\n",
    "            param.bias.requires_grad = requires_grad\n",
    "\n",
    "    elif setting == \"zeros\":\n",
    "        param.weight = torch.nn.Parameter(torch.zeros(*param.weight.shape).to(device))\n",
    "        param.weight.requires_grad = requires_grad\n",
    "        if bias:\n",
    "            param.bias = torch.nn.Parameter(torch.zeros(*param.bias.shape).to(device))\n",
    "            param.bias.requires_grad = requires_grad\n",
    "            \n",
    "    elif setting == \"ones\":\n",
    "        param.weight = torch.nn.Parameter(torch.zeros(*param.weight.shape).to(device))\n",
    "        param.weight.requires_grad = requires_grad\n",
    "        if bias:\n",
    "            param.bias = torch.nn.Parameter(torch.ones(*param.bias.shape).to(device))\n",
    "            param.bias.requires_grad = requires_grad\n",
    "            \n",
    "    elif isinstance(setting, torch.Tensor):\n",
    "        assert setting.shape == param.shape\n",
    "        param.data = setting.clone().to(device)\n",
    "        param.requires_grad = requires_grad\n",
    "\n",
    "# These functions assume a Conv1d (i.e. \"short\") implementation of BaseConv\n",
    "def set_conv_param(param, setting=None, requires_grad=False, device=\"cuda\"):\n",
    "    if setting == \"identity\":\n",
    "        param.weight = torch.nn.Parameter(torch.zeros(*param.weight.shape).to(device))\n",
    "        param.weight.data[..., -1] = 1\n",
    "        param.bias.data = torch.nn.Parameter(torch.zeros(*param.bias.shape).to(device))\n",
    "    elif setting == \"zeros\":\n",
    "        param.weight.data = torch.nn.Parameter(torch.zeros(*param.weight.shape).to(device))\n",
    "        param.bias.data = torch.nn.Parameter(torch.zeros(*param.bias.shape).to(device))\n",
    "        \n",
    "def initialize_weights(model, layer=None, setting=None, var=None, device=\"cuda\"):\n",
    "\n",
    "    if layer is None and setting is None:\n",
    "        # Manually set weights\n",
    "        set_param(model._read_in, setting=\"identity\", device=device)\n",
    "        set_param(model._read_out, setting=\"identity\", device=device)\n",
    "        set_param(model._backbone.transformer.wpe, setting=\"zeros\", bias=False, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "sampler = LeastSquaresSampler(n_dims=n_dims, device=device)\n",
    "a, x, x_init, b = sampler.sample(n_points=n_points, batch_size=batch_size)\n",
    "\n",
    "task = ExplicitGradient(setting=\"last\")\n",
    "task_data = task.evaluate(sample_data=(a, x.clone(), x_init, b))\n",
    "in_seq = task_data[\"in\"][:, 1:]\n",
    "out_grad = task_data[\"out\"]\n",
    "\n",
    "# Sanity check: Ax = b\n",
    "print(torch.norm(torch.einsum(\"b l d, b d -> b l\", a, x.squeeze(-1)) - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard gradient descent\n",
    "preds = []\n",
    "pred_xs = []\n",
    "\n",
    "layer_in = in_seq.clone()\n",
    "x_pred = x_init\n",
    "\n",
    "for iter_i in range(num_iters):\n",
    "    grad = einsum(\n",
    "        einsum(x_pred, a, \"b d, b l d -> b l\") - b, # (b l)\n",
    "        a,\n",
    "        \"b l, b l d -> b d\"\n",
    "    ) * 2/(n_points)\n",
    "    x_pred = x_pred - lr*grad\n",
    "    pred = einsum(x_pred, a[:, -1], \"b d, b d -> b\")\n",
    "    preds.append(pred)\n",
    "    pred_xs.append(x_pred.clone())\n",
    "\n",
    "preds = torch.stack(preds, dim=0) # (num_iters, B)\n",
    "pred_xs = torch.stack(pred_xs, dim=0) # (num_iters, B, D)\n",
    "errors = ((preds - b[:, -1])**2).detach().cpu().numpy() # (num_iters, B)\n",
    "errors_gd_25 = np.percentile(errors, 25, axis=1)\n",
    "errors_gd_75 = np.percentile(errors, 75, axis=1)\n",
    "errors_gd = np.median(errors, axis=1)\n",
    "\n",
    "plt.plot(errors_gd, label=\"GD\")\n",
    "plt.title(\"Gradient Descent\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"# iters\")\n",
    "plt.ylabel(\"MSE of final prediction\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final error: {errors_gd[-1].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal BaseConv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_conf(\n",
    "    n_layer=3,\n",
    "    n_embd=128,\n",
    "    n_dims=5,\n",
    "    n_points=21,\n",
    "):\n",
    "    model_conf = Munch(\n",
    "        family=\"gpt2\",\n",
    "        n_dims=n_dims,\n",
    "        n_positions=n_points,\n",
    "        n_embd=n_embd,\n",
    "        n_layer=n_layer,\n",
    "        n_head=1,\n",
    "        use_mlps=False,\n",
    "        seq_op=\"base_conv\",\n",
    "        mlp_activ=\"gelu\",\n",
    "        use_resid=False,\n",
    "        use_seqop_ln=False,\n",
    "        use_final_ln=False,\n",
    "        use_mlp_ln=False,\n",
    "        conv_type=\"short\",\n",
    "        causal=True,\n",
    "        train_proj=False,\n",
    "        train_pos=False,\n",
    "        mlp_upfactor=2,\n",
    "        in_dims=n_dims,\n",
    "        out_dims=n_dims,\n",
    "        use_softmax_for_attn=True,\n",
    "    )\n",
    "    return model_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = build_model_conf(\n",
    "    n_layer=n_layer,\n",
    "    n_embd=n_embd,\n",
    "    n_dims=n_model_dims,\n",
    "    n_points=n_points,\n",
    ")\n",
    "\n",
    "model = build_model(model_conf).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv1d implementation\n",
    "\n",
    "# Manually set model params\n",
    "\n",
    "# Initial embed\n",
    "initialize_weights(model)\n",
    "\n",
    "# Layer 1\n",
    "# In proj\n",
    "# weight\n",
    "temp = torch.zeros((n_embd, n_embd))\n",
    "temp[2*n_dims+1:3*n_dims+1, :n_dims] = torch.eye(n_dims)\n",
    "temp[:2*n_dims+1, :2*n_dims+1] = torch.eye(2*n_dims+1)\n",
    "set_param(model._backbone.transformer.h[0].seq_mixer.base_conv.in_proj.weight, setting=temp, requires_grad=False, device=device)\n",
    "# Conv\n",
    "set_conv_param(model._backbone.transformer.h[0].seq_mixer.base_conv.conv.conv, setting=\"identity\", requires_grad=False, device=device)\n",
    "# Dot proj\n",
    "# weight\n",
    "temp = torch.zeros((n_embd, n_embd))\n",
    "temp[2*n_dims+1:3*n_dims+1, n_dims+1:2*n_dims+1] = torch.eye(n_dims)\n",
    "set_param(model._backbone.transformer.h[0].seq_mixer.base_conv.projection.weight, setting=temp, requires_grad=False, device=device) # identity, zeros, ones\n",
    "# bias\n",
    "temp = torch.zeros((n_embd))\n",
    "temp[:2*n_dims+1] = 1\n",
    "set_param(model._backbone.transformer.h[0].seq_mixer.base_conv.projection.bias, setting=temp, requires_grad=False, device=device)\n",
    "# Out proj\n",
    "# weight\n",
    "temp = torch.zeros((n_embd, n_embd))\n",
    "temp[3*n_dims+1:, 2*n_dims+1:3*n_dims+1] = 1\n",
    "temp[3*n_dims+1:, n_dims] = -1\n",
    "temp[:3*n_dims+1, :3*n_dims+1] = torch.eye(3*n_dims+1)\n",
    "set_param(model._backbone.transformer.h[0].seq_mixer.base_conv.out_proj.weight, setting=temp, requires_grad=False, device=device)\n",
    "\n",
    "# Layer 2\n",
    "# In proj\n",
    "set_param(model._backbone.transformer.h[1].seq_mixer.base_conv.in_proj, setting=\"identity\", bias=True, requires_grad=False, device=device)\n",
    "# Conv\n",
    "set_conv_param(model._backbone.transformer.h[1].seq_mixer.base_conv.conv.conv, setting=\"identity\", requires_grad=False, device=device)\n",
    "# Dot proj\n",
    "# weight\n",
    "temp = torch.zeros((n_embd, n_embd))\n",
    "temp[3*n_dims+1:, :n_dims] = torch.eye(n_dims)\n",
    "set_param(model._backbone.transformer.h[1].seq_mixer.base_conv.projection.weight, setting=temp, requires_grad=False, device=device)\n",
    "# bias\n",
    "temp = torch.zeros((n_embd))\n",
    "temp[:3*n_dims+1] = 1\n",
    "set_param(model._backbone.transformer.h[1].seq_mixer.base_conv.projection.bias, setting=temp, requires_grad=False, device=device)\n",
    "# Out proj\n",
    "set_param(model._backbone.transformer.h[1].seq_mixer.base_conv.out_proj, setting=\"identity\", bias=True, requires_grad=False, device=device)\n",
    "\n",
    "# Layer 3\n",
    "# In proj\n",
    "set_param(model._backbone.transformer.h[2].seq_mixer.base_conv.in_proj, setting=\"identity\", bias=True, requires_grad=False, device=device)\n",
    "# Conv\n",
    "# weight\n",
    "temp = torch.zeros(*model._backbone.transformer.h[2].seq_mixer.base_conv.conv.conv.weight.shape)\n",
    "temp[:, :, -1] = 1\n",
    "temp[3*n_dims+1:] = 1\n",
    "set_param(model._backbone.transformer.h[2].seq_mixer.base_conv.conv.conv.weight, setting=temp, requires_grad=False, device=device)\n",
    "# bias\n",
    "temp = torch.zeros(*model._backbone.transformer.h[2].seq_mixer.base_conv.conv.conv.bias.shape)\n",
    "set_param(model._backbone.transformer.h[2].seq_mixer.base_conv.conv.conv.bias, setting=temp, requires_grad=False, device=device)\n",
    "# Dot proj\n",
    "set_param(model._backbone.transformer.h[2].seq_mixer.base_conv.projection, setting=\"ones\", bias=True, requires_grad=False, device=device)\n",
    "# Out proj\n",
    "# weight\n",
    "temp = torch.zeros((n_embd, n_embd))\n",
    "temp[:2*n_dims+1, :2*n_dims+1] = torch.eye(2*n_dims+1)\n",
    "temp[n_dims+1:2*n_dims+1, 3*n_dims+1:] = -lr * torch.eye(n_dims)\n",
    "set_param(model._backbone.transformer.h[2].seq_mixer.base_conv.out_proj.weight, setting=temp, requires_grad=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually pass through model\n",
    "out_seq = model._read_in(in_seq)\n",
    "initial_input = out_seq.clone()\n",
    "\n",
    "# Init w_hat guess\n",
    "out_seq[:, :, n_dims+1:2*n_dims+1] = x_init[:, None, :]\n",
    "\n",
    "preds = []\n",
    "pred_xs = []\n",
    "data_deviations = []\n",
    "\n",
    "for iter_i in range(num_iters):\n",
    "    out_seq = model._backbone.transformer.h[0](out_seq)\n",
    "    out_seq = model._backbone.transformer.h[1](out_seq)\n",
    "    out_seq = model._backbone.transformer.h[2](out_seq)\n",
    "\n",
    "    # How much has the initial data deviated?\n",
    "    data_deviation = (initial_input - out_seq)[0, :, :n_dims+1].norm(dim=-1).square().mean().item()\n",
    "    data_deviations.append(data_deviation)\n",
    "\n",
    "    pred_w = out_seq[:, -1, n_dims+1:2*n_dims+1].clone().detach()\n",
    "\n",
    "    if iter_i < 1:\n",
    "        print(f\"Iter {iter_i}: w_hat = {pred_w[0]}\")\n",
    "        print(f\"Iter {iter_i}: data deviation = {data_deviation}\")\n",
    "\n",
    "    pred = einsum(pred_w, a[:, -1], \"b d, b d -> b\")\n",
    "    preds.append(pred)\n",
    "    pred_xs.append(pred_w.clone())\n",
    "\n",
    "preds = torch.stack(preds, dim=0) # (num_iters, B)\n",
    "pred_xs = torch.stack(pred_xs, dim=0) # (num_iters, B, D)\n",
    "errors = ((preds - b[:, -1])**2).detach().cpu().numpy() # (num_iters, B)\n",
    "errors_baseconv_25 = np.percentile(errors, 25, axis=1)\n",
    "errors_baseconv_75 = np.percentile(errors, 75, axis=1)\n",
    "errors_baseconv = np.median(errors, axis=1)\n",
    "\n",
    "# Colors\n",
    "color_baseconv = mcolors.rgb_to_hsv(mcolors.to_rgb('orange'))\n",
    "color_gd = mcolors.rgb_to_hsv(mcolors.to_rgb('blue'))\n",
    "\n",
    "# Plot\n",
    "# BaseConv\n",
    "plt.plot(errors_baseconv, label=\"BaseConv\", color=\"orange\")\n",
    "plt.fill_between(list(range(len(errors_baseconv))), errors_baseconv_25, errors_baseconv_75, alpha=0.2, color=adjust_lightness(color_baseconv, lightness=0.75))\n",
    "# GD\n",
    "plt.plot(errors_gd, label=\"GD\", color=\"blue\")\n",
    "plt.fill_between(list(range(len(errors_gd))), errors_gd_25, errors_gd_75, alpha=0.2, color=adjust_lightness(color_gd, lightness=0.75))\n",
    "plt.title(\"Gradient Descent\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"# iters (= # layers / 3)\")\n",
    "plt.ylabel(\"MSE of final prediction\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final error: {errors_baseconv[-1].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl_odes_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
